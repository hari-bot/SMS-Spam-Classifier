{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "123ee7a1",
   "metadata": {},
   "source": [
    "# SMS Spam Classifier: Phase 4\n",
    "## In this phase, we'll continue building our spam classifier by:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c0c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the training data from a CSV file\n",
    "training_data = pd.read_csv('sms_spam.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d5ae88",
   "metadata": {},
   "source": [
    "## Section 1: Model Selection\n",
    "\n",
    "### Choosing the Machine Learning Algorithm\n",
    "\n",
    "For our SMS text classification project, the selection of the appropriate machine learning algorithm is a critical decision that significantly influences the model's effectiveness. We have chosen the Multinomial Naive Bayes algorithm for several reasons:\n",
    "\n",
    "### Multinomial Naive Bayes Algorithm\n",
    "\n",
    "Multinomial Naive Bayes is a probabilistic algorithm that finds applications in various fields, with particular suitability for text classification tasks. Here's a brief overview of the algorithm:\n",
    "\n",
    "1)Multinomial Distribution: The algorithm is founded on the assumption that the features (in our case, words in SMS messages) are generated from a multinomial distribution. This assumption makes it well-suited for discrete data, common in text analysis, where we count the occurrences of words.\n",
    "\n",
    "2)Naive Bayes Assumption: The \"naive\" part of its name comes from the assumption of conditional independence between features. It operates under the presumption that the presence or absence of a particular word in a message is independent of the presence or absence of other words, given the class label. This simplification streamlines the probability calculations, making it computationally efficient.\n",
    "\n",
    "3)Feature Vector Representation: In text classification, each document (SMS message) is represented as a feature vector, with each feature corresponding to a word or term. The value of each feature represents the frequency (or other statistics) of that word in the document.\n",
    "\n",
    "4)Parameter Estimation: The algorithm estimates parameters from the training data, including the probabilities of each word occurring in spam and non-spam messages. These estimates are used to make predictions.\n",
    "\n",
    "Our choice of Multinomial Naive Bayes is driven by its efficiency and relevance to text classification. However, we acknowledge its limitations and plan to interpret results while considering them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9865d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes classifier\n",
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b250925",
   "metadata": {},
   "source": [
    "## Section 2: Model Training\n",
    "\n",
    "### Data Splitting\n",
    "\n",
    "To train and evaluate our Multinomial Naive Bayes model, we began by splitting the dataset into a training set and a testing set. This step is essential for assessing the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be6c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_data['text']\n",
    "y_train = training_data['type'] \n",
    "\n",
    "X_train_vectorized = tfidf_vectorizer.transform(X_train)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_vectorized, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95091c07",
   "metadata": {},
   "source": [
    "##  Model Training\n",
    "With the training data prepared, we proceeded to train our Multinomial Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3461bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662ed07",
   "metadata": {},
   "source": [
    "The model is now ready for evaluation in the next phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee437b1",
   "metadata": {},
   "source": [
    "## Section 3: Model Evaluation\n",
    "\n",
    "### Performance Metrics\n",
    "\n",
    "To assess the performance of our Multinomial Naive Bayes model, we employed common text classification metrics. These metrics provide a quantitative measure of how well the model can distinguish between \"spam\" and \"ham\" messages. We focused on the following metrics:\n",
    "\n",
    "1)Accuracy: Measures the proportion of correctly classified messages.\n",
    "\n",
    "2)Precision: Measures the ability of the model to correctly identify \"spam\" messages, minimizing false positives.\n",
    "\n",
    "3)Recall: Measures the model's ability to identify all \"spam\" messages, minimizing false negatives.\n",
    "\n",
    "4)F1-Score: Combines precision and recall into a single metric, considering both false positives and false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a401af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.04%\n",
      "Precision: 100.00%\n",
      "Recall: 78.00%\n",
      "F1-Score: 87.64%\n"
     ]
    }
   ],
   "source": [
    "# Section 3: Model Evaluation\n",
    "# Performance Metrics\n",
    "\n",
    "# Predict using the trained model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=\"spam\")\n",
    "recall = recall_score(y_test, y_pred, pos_label=\"spam\")\n",
    "f1 = f1_score(y_test, y_pred, pos_label=\"spam\")\n",
    "\n",
    "# Results\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1-Score: {f1 * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc2c083",
   "metadata": {},
   "source": [
    "These metrics provide a comprehensive view of the model's performance in distinguishing between \"spam\" and \"ham\" messages."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
